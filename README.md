# ğŸ§ Emotion-Aware Music Recommendation System

### MSc Computer Science Final Project

This project develops an **emotion-aware music recommendation system** that suggests songs based on the listenerâ€™s emotional state, inferred directly from audio features.

By combining **music emotion recognition (MER)** techniques with a **content-based recommendation approach**, the system predicts the emotional characteristics of songs â€” measured through *valence* (positivity/negativity) and *arousal* (energy/intensity) â€” and recommends tracks whose emotional profiles best match or complement a userâ€™s mood.

---

## ğŸ” Project Overview

### ğŸ¯ Objective
To design and evaluate a music recommendation system that predicts and leverages song emotions derived from audio features to enhance user experience in mood-based music discovery.

### ğŸ§  Methodology
1. **Data Collection** â€“ Use publicly available emotion-annotated music datasets (e.g., DEAM) and Spotifyâ€™s audio feature API.  
2. **Feature Extraction** â€“ Extract spectral, rhythmic, and timbral features using `librosa` and merge with Spotify metadata.  
3. **Emotion Prediction** â€“ Train regression models to predict *valence* and *arousal* scores from extracted features.  
4. **Recommendation** â€“ Recommend songs closest to the userâ€™s input mood in the valenceâ€“arousal space.  
5. **Evaluation** â€“ Assess model accuracy (RMSE, correlation) and recommendation quality through user feedback.

---

## ğŸ§© Tech Stack
- **Python** â€“ Core development  
- **Librosa** â€“ Audio feature extraction  
- **Scikit-learn** â€“ Machine learning models  
- **Spotify API (Spotipy)** â€“ Song metadata and features  
- **Pandas / NumPy** â€“ Data processing  
- **Matplotlib / Seaborn** â€“ Visualisation and analysis  
- **Jupyter Notebook** â€“ Experimentation environment  

---

## ğŸ“‚ Project Structure
